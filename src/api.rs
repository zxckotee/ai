use actix_web::{web, App, HttpServer, Responder, HttpResponse};
use crate::trusted_scraper::TrustedScraper;
use crate::active_learning::{ActiveLearning, Correction};
use crate::knowledge_graph::KnowledgeGraph;
use crate::text_processor::TextProcessor;
use crate::embedding_cache::EmbeddingCache;
use serde::{Serialize, Deserialize};
use std::sync::Mutex;
use petgraph::visit::EdgeRef;

/// –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞
#[derive(Deserialize)]
pub struct ProcessTextRequest {
    pub text: String,
    pub learn: Option<bool>,
    pub annotation: Option<String>,
}

/// –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –æ–±—É—á–µ–Ω–∏—è
#[derive(Deserialize)]
pub struct LearnRequest {
    pub text: String,
    pub annotation: String,
    pub user: String,
}

/// –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏
#[derive(Deserialize)]
pub struct VerifyRequest {
    pub fact: String,
    pub source: Option<String>,
}

/// –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –≥—Ä–∞—Ñ–∞
#[derive(Serialize)]
struct GraphExport {
    nodes: Vec<String>,
    edges: Vec<(usize, usize, String)>,
    stats: GraphStats,
}

/// –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≥—Ä–∞—Ñ–∞
#[derive(Serialize)]
struct GraphStats {
    total_nodes: usize,
    total_edges: usize,
    entity_types: Vec<String>,
    action_types: Vec<String>,
}

/// –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞
async fn process_text(
    processor: web::Data<Mutex<TextProcessor>>,
    req: web::Json<ProcessTextRequest>,
) -> impl Responder {
    let mut processor = processor.lock().unwrap();
    
    match processor.process_text(&req.text).await {
        result => {
            // –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ –æ–±—É—á–µ–Ω–∏–µ
            if req.learn.unwrap_or(false) {
                let annotation = req.annotation.as_deref().unwrap_or("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ");
                let learned = processor.learn_from_text(&req.text, annotation).await;
                
                HttpResponse::Ok().json(serde_json::json!({
                    "success": true,
                    "result": result,
                    "learned": learned,
                    "message": if learned { "–§–∞–∫—Ç –¥–æ–±–∞–≤–ª–µ–Ω –≤ –≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π" } else { "–§–∞–∫—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏—é" }
                }))
            } else {
                HttpResponse::Ok().json(serde_json::json!({
                    "success": true,
                    "result": result
                }))
            }
        }
    }
}

/// –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
async fn learn_from_text(
    processor: web::Data<Mutex<TextProcessor>>,
    req: web::Json<LearnRequest>,
) -> impl Responder {
    let mut processor = processor.lock().unwrap();
    
    match processor.learn_from_text(&req.text, &req.annotation).await {
        true => HttpResponse::Ok().json(serde_json::json!({
            "success": true,
            "message": "–§–∞–∫—Ç —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω –≤ –≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π",
            "text": req.text,
            "annotation": req.annotation
        })),
        false => HttpResponse::Accepted().json(serde_json::json!({
            "success": false,
            "message": "–§–∞–∫—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏—é",
            "text": req.text,
            "annotation": req.annotation
        }))
    }
}

/// –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–∫—Ç–æ–≤
async fn verify_fact(
    processor: web::Data<Mutex<TextProcessor>>,
    req: web::Json<VerifyRequest>,
) -> impl Responder {
    let processor = processor.lock().unwrap();
    
    match processor.verify_fact(&req.fact).await {
        true => HttpResponse::Ok().json(serde_json::json!({
            "success": true,
            "verified": true,
            "fact": req.fact,
            "message": "–§–∞–∫—Ç –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω —á–µ—Ä–µ–∑ TrustedScraper"
        })),
        false => HttpResponse::Ok().json(serde_json::json!({
            "success": true,
            "verified": false,
            "fact": req.fact,
            "message": "–§–∞–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö"
        }))
    }
}

/// –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∞–∫—Ç–æ–≤ (—Å—Ç–∞—Ä—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç)
async fn check_fact(scraper: web::Data<TrustedScraper>, info: web::Query<Correction>) -> impl Responder {
    let al = ActiveLearning::new(&scraper);
    let res = al.check_correction(&info.into_inner()).await;
    match res {
        crate::active_learning::CorrectionResult::AutoAccepted => HttpResponse::Ok().body("Accepted automatically"),
        crate::active_learning::CorrectionResult::NeedsModeration => HttpResponse::Ok().body("Needs moderation"),
        crate::active_learning::CorrectionResult::Rejected => HttpResponse::Ok().body("Rejected"),
    }
}

/// –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –º–æ–¥–µ—Ä–∞—Ü–∏–∏ (–∑–∞–≥–ª—É—à–∫–∞)
async fn moderate_fact(_scraper: web::Data<TrustedScraper>, _info: web::Query<Correction>) -> impl Responder {
    HttpResponse::Ok().body("Moderation interface (TODO)")
}

/// –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –≥—Ä–∞—Ñ–∞ –∑–Ω–∞–Ω–∏–π
async fn export_graph(graph: web::Data<Mutex<KnowledgeGraph>>) -> impl Responder {
    let graph = graph.lock().unwrap();
    let mut nodes = Vec::new();
    let mut edges = Vec::new();
    let mut entity_types = Vec::new();
    let mut action_types = Vec::new();
    
    for idx in graph.graph.node_indices() {
        let seg = &graph.graph[idx];
        nodes.push(format!("{:?}", seg));
        
        // –ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–æ–≤ —É–∑–ª–æ–≤
        match seg {
            crate::segment::Segment::Primitive(text) => {
                if text.contains("–∫–æ—Ç") || text.contains("—Ä—ã–±–∞") {
                    entity_types.push("–∂–∏–≤–æ—Ç–Ω–æ–µ".to_string());
                }
            },
            crate::segment::Segment::Composite(_) => {
                action_types.push("–¥–µ–π—Å—Ç–≤–∏–µ".to_string());
            },
            _ => {}
        }
    }
    
    for edge in graph.graph.edge_references() {
        let (a, b) = (edge.source().index(), edge.target().index());
        edges.push((a, b, edge.weight().clone()));
    }
    
    let stats = GraphStats {
        total_nodes: nodes.len(),
        total_edges: edges.len(),
        entity_types,
        action_types,
    };
    
    let export = GraphExport { nodes, edges, stats };
    HttpResponse::Ok().json(export)
}

/// –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–µ—à–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
async fn cache_stats() -> impl Responder {
    let stats = EmbeddingCache::get_cache_stats();
    HttpResponse::Ok().json(stats)
}

/// –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∫–µ—à–∞
async fn clear_cache() -> impl Responder {
    EmbeddingCache::cleanup_old_embeddings(0); // –û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ
    HttpResponse::Ok().json(serde_json::json!({
        "success": true,
        "message": "–ö–µ—à —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –æ—á–∏—â–µ–Ω"
    }))
}

/// –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
#[derive(Deserialize)]
struct SimilarityRequest {
    text: String,
    top_k: Option<usize>,
}

async fn find_similar(
    req: web::Json<SimilarityRequest>,
) -> impl Responder {
    let query_embedding = EmbeddingCache::get_cached_embedding(&req.text);
    let top_k = req.top_k.unwrap_or(5);
    
    // –ü—Ä–∏–º–µ—Ä –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö)
    let sample_embeddings = vec![
        EmbeddingCache::get_cached_embedding("–∫–æ—Ç"),
        EmbeddingCache::get_cached_embedding("–∫–æ—à–∫–∞"),
        EmbeddingCache::get_cached_embedding("—Å–æ–±–∞–∫–∞"),
        EmbeddingCache::get_cached_embedding("—Ä—ã–±–∞"),
    ];
    
    let similar = EmbeddingCache::find_similar_embeddings(&query_embedding, &sample_embeddings, top_k);
    
    let results: Vec<serde_json::Value> = similar.iter().map(|(idx, similarity)| {
        serde_json::json!({
            "index": idx,
            "similarity": similarity,
            "text": match *idx {
                0 => "–∫–æ—Ç",
                1 => "–∫–æ—à–∫–∞", 
                2 => "—Å–æ–±–∞–∫–∞",
                3 => "—Ä—ã–±–∞",
                _ => "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
            }
        })
    }).collect();
    
    HttpResponse::Ok().json(serde_json::json!({
        "query": req.text,
        "top_k": top_k,
        "results": results
    }))
}

/// –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã
async fn health_check() -> impl Responder {
    HttpResponse::Ok().json(serde_json::json!({
        "status": "healthy",
        "version": "0.1.0",
        "components": {
            "text_processor": "active",
            "embedding_cache": "active", 
            "knowledge_graph": "active",
            "trusted_scraper": "active"
        }
    }))
}

/// –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∏—Å—Ç–µ–º–µ
async fn system_info() -> impl Responder {
    let cache_stats = EmbeddingCache::get_cache_stats();
    
    HttpResponse::Ok().json(serde_json::json!({
        "system": "Metastasa - –ú—ã—Å–ª—è—â–µ–µ –Ø–¥—Ä–æ",
        "version": "0.1.0",
        "architecture": {
            "language": "Rust",
            "framework": "actix-web",
            "gpu": "Burn WGPU",
            "storage": "sled + petgraph"
        },
        "cache_stats": cache_stats,
        "features": [
            "GPU Attention",
            "–õ–æ–≥–∏—á–µ—Å–∫–∏–µ –≥—Ä–∞—Ñ—ã –∑–Ω–∞–Ω–∏–π", 
            "TrustedScraper",
            "Active Learning",
            "–ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"
        ]
    }))
}

pub async fn run_api() -> std::io::Result<()> {
    let scraper = TrustedScraper::new();
    let graph = web::Data::new(Mutex::new(KnowledgeGraph::new(sled::Config::new().temporary(true).open().unwrap())));
    let processor = web::Data::new(Mutex::new(TextProcessor::new()));
    
    println!("üöÄ –ó–∞–ø—É—Å–∫ REST API —Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞ http://127.0.0.1:8080");
    println!("üìö –î–æ—Å—Ç—É–ø–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã:");
    println!("  POST /process    - –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞");
    println!("  POST /learn      - –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö");
    println!("  POST /verify     - –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è —Ñ–∞–∫—Ç–æ–≤");
    println!("  GET  /graph      - –≠–∫—Å–ø–æ—Ä—Ç –≥—Ä–∞—Ñ–∞ –∑–Ω–∞–Ω–∏–π");
    println!("  GET  /cache      - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–µ—à–∞");
    println!("  POST /clear      - –û—á–∏—Å—Ç–∫–∞ –∫–µ—à–∞");
    println!("  GET  /similar    - –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤");
    println!("  GET  /health     - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è");
    println!("  GET  /info       - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ");
    
    HttpServer::new(move || {
        App::new()
            .app_data(web::Data::new(scraper.clone()))
            .app_data(graph.clone())
            .app_data(processor.clone())
            .route("/process", web::post().to(process_text))
            .route("/learn", web::post().to(learn_from_text))
            .route("/verify", web::post().to(verify_fact))
            .route("/check", web::get().to(check_fact))
            .route("/moderate", web::get().to(moderate_fact))
            .route("/graph", web::get().to(export_graph))
            .route("/cache", web::get().to(cache_stats))
            .route("/clear", web::post().to(clear_cache))
            .route("/similar", web::post().to(find_similar))
            .route("/health", web::get().to(health_check))
            .route("/info", web::get().to(system_info))
    })
    .bind(("127.0.0.1", 8080))?
    .run()
    .await
} 